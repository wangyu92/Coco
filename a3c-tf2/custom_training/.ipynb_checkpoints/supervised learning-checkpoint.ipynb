{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "True\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "%load_ext tensorboard\n",
    "print(tf.__version__)\n",
    "print(tf.executing_eagerly())\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              3072      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 1,053,697\n",
      "Trainable params: 1,053,697\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(2,))\n",
    "hidden1 = keras.layers.Dense(1024, activation=tf.nn.relu)(inputs)\n",
    "hidden2 = keras.layers.Dense(1024, activation=tf.nn.relu)(hidden1)\n",
    "outputs = keras.layers.Dense(1)(hidden2)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(0.001)\n",
    "ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=optimizer, net=model)\n",
    "manager = tf.train.CheckpointManager(ckpt, './tf_ckpts', max_to_keep=3)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./tf_ckpts/ckpt-401831', './tf_ckpts/ckpt-401832', './tf_ckpts/ckpt-401833']\n"
     ]
    }
   ],
   "source": [
    "print(manager.checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./tf_ckpts/ckpt-401833\n",
      "Restored from ./tf_ckpts/ckpt-401833\n"
     ]
    }
   ],
   "source": [
    "lastest_checkpoint = manager.checkpoints[-1]\n",
    "print(lastest_checkpoint)\n",
    "if lastest_checkpoint:\n",
    "    ckpt.restore(lastest_checkpoint)\n",
    "    print(\"Restored from {}\".format(lastest_checkpoint))\n",
    "else:\n",
    "    print(\"Initializing from scrach.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(labels, preds):\n",
    "    subs = labels - preds\n",
    "    square = tf.math.pow(subs, 2)\n",
    "    sums = tf.math.reduce_sum(square)\n",
    "    mse = sums / labels.shape[0]\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=301, shape=(), dtype=float64, numpy=6.079999999999994>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.array([41, 45, 49, 47, 44])\n",
    "preds = np.array([43.6, 44.4, 45.2, 46, 46.8])\n",
    "mse(labels, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39.056427]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([50., 40])\n",
    "model.predict(np.expand_dims(x, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the metrics\n",
    "loss_metric = keras.metrics.Mean(name='train_loss')\n",
    "\n",
    "# -- tensorboard --\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = 'log/gradient_tape/' + current_time + 'train'\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "\n",
    "def train_step(inputs, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(tf.expand_dims(inputs, axis=0), training=True)\n",
    "        pred_loss = mse(labels, predictions)\n",
    "    \n",
    "    gradients = tape.gradient(pred_loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    # Update the metrics\n",
    "    loss_metric.update_state(pred_loss)\n",
    "    return pred_loss\n",
    "    \n",
    "train_data = []\n",
    "for i in range(1000):\n",
    "    m = np.random.randint(1, high=1000)\n",
    "    inputs = np.array([i, m], dtype=np.float32)\n",
    "    labels = np.array([i * 2 if i < m else m], dtype=np.float32)\n",
    "    data = (inputs, labels)\n",
    "    \n",
    "    train_data.append(data)\n",
    "    \n",
    "for epoch in range(10000):\n",
    "    # Reset the metrics\n",
    "    loss_metric.reset_states()\n",
    "    \n",
    "    for inputs, labels in train_data:\n",
    "        loss = train_step(inputs, labels)\n",
    "        ckpt.step.assign_add(1)\n",
    "        if int(ckpt.step) % 10 == 0:\n",
    "            save_path = manager.save()\n",
    "#             print(\"Saved checkpoint for step {}:{}\".format(int(ckpt.step), save_path))\n",
    "#             print(\"loss {:1.2f}\".format(loss.numpy()))\n",
    "    \n",
    "    mean_loss = loss_metric.result()\n",
    "#     print(\"Epoch : \", epoch)\n",
    "#     print(\"Loss : {:.3f}\".format(mean_loss))\n",
    "    \n",
    "    with train_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', mean_loss, step=epoch)\n",
    "  \n",
    "# 간단하게 모델이 수렴할 수 있도록 해줌.\n",
    "# model.save_weights('esay_checkpoint')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
